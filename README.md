# SoundUML - Module For Modelio Open Source

SoundUML is a proof of concept tool for Modelio, that allows UML class diagrams to be read to the users, through the usage of voice synthesis and sound playback.

It is a prototype module, developed for a master's thesis whose goal is to build a foundational framework of principles designed to ground decisions when constructing auditory notations. This work is based on the knowledge of music symbology and understanding of the semiotics of the audible field, combined with the insights provided by Daniel Moody in *The “Physics” of Notations: Toward a Scientific Basis for Constructing Visual Notations in Software Engineering*, together with the findings of other research and developed tools concerning these topics. 

SoundUML was created with the primary purpose of serving as a testing instrument, in order to understand if our proposals for diagrammatic readings are effective when compared to the common, visual approach. It was also created to help draw conclusions regarding the validation of the principles for an auditory notation proposed during the dissertation, while testing the feasibility and usability of working with sound and voice synthesis when using UML, more specifically Class diagrams. Additionally, it aims to contribute to the inclusion of visually impaired and blind people in activities of this type.   

This diagrammatic reading is based on two experimental studies that we have conducted during the dissertation. The first study was aimed at detecting any emerging patterns regarding how people read UML Class and state diagrams. According to those conclusions, we implemented the reading that the TTS provides to the users. The second consisted in preparing two catalogues of sounds for the different elements that constitute a UML Class diagram. One follows the aforementioned knowledge of music symbology, semiotics and Moody's work, while the other, disregards said auditory principles and semiotics, with the sounds being chosen arbitrarily. By comparing both, we hoped to achieve greater efficacy regarding the perception of different sounds on behalf of users. The sounds that provided the best results, were then incorporated into this tool.


A future second phase would permit the editing of said diagrams with the usage of Google's Speech To Text API, along with further improvements to the tool's usability.
